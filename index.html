<!DOCTYPE html>
<html lang="en">

  <head>
    <title>
      UnImplicit: Understanding Implicit and Underspecified Language
    </title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Prevent caching -->
    <META HTTP-EQUIV="Pragma" CONTENT="no-cache">
    <META HTTP-EQUIV="Expires" CONTENT="-1">
    <link href="bootstrap/css/bootstrap.min.css" rel="stylesheet" media="screen">
    
    <style>
      /* Customize container */
      @media (min-width: 968px) {
	  .container {
	      max-width: 968px;
	  }
      }
      .container-narrow > hr {
	  margin: 30px 0;
      }
      
      /* Customize dropdown menu */
      .dropdown {
	  cursor: pointer;
      }
      .dropdown sup {
	  color: rgb(66, 139, 202);
      }
      .dropdown sup:hover, .dropdown sup:focus {
	  color: rgb(42, 100, 150);
	  text-decoration: underline;
      }
      .dropdown-menu {
	  min-width: 500px;
	  left: -200px;
      }
      .dropdown-menu li {
	  margin-bottom: .5em;
	  /*border-top-style:solid; padding-left:10px;*/
      }
    </style>
  </head>
  
  <body data-spy="scroll" data-target="#navbar" data-offset="70" onload="load()">
    
    <nav class="navbar navbar-default navbar-fixed-top" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="#">UnImplicit</a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
	    <li><a href="#speakers">Invited Talks</a></li>
            <li><a href="#task">Shared Task</a></li>
	    <!--li><a href="#call">Call</a></li-->
	    <!--li><a href="#papers">Papers</a></li-->
            <li><a href="#program">Program</a></li>
	    <li><a href="#dates">Dates</a></li>
            <li><a href="#organizers">Organizers &amp; Committee</a></li>
          </ul>
          <ul class="nav navbar-nav navbar-right">
            <!--li><a href="https://www.emnlp-ijcnlp2019.org/">EMNLP-IJCNLP 2019</a></li-->
          </ul>
        </div>
      </div>
    </nav>
    
    <div class="container">
      
      <br/>
      <br/>      
      <br/>
      <center><h2 id="top"><b>UnImplicit: The First Workshop on<br/>
	    Understanding Implicit and Underspecified Language</b></h2></center>
      <center><h4>Workshop to be held online in conjunction with ACL-IJCNLP 2021</h4></center>
      <br/>
      <br/>
      <div class="alert alert-success" role="alert">
	<strong>Update 5 August 2021: </strong>Thank you very much to all participants! If you want to sign up for our mailing list, click <a href="https://docs.google.com/forms/d/e/1FAIpQLSdpcgkYhcUHtKvQLO-kmnrq9P_HI3HhSSpSWtpa6XmkoMs2tQ/viewform">here</a>.
	<!--strong>Update 3 August 2021: </strong>We finalized the program, including working group topics! Details can be found <a href="#program">here</a-->
	<!--strong>Update 30 July 2021: </strong>We set up a survey for anyone interested in attending our working group sessions <a href="https://docs.google.com/forms/d/e/1FAIpQLScuIo3ITDr-GUWY93aW59x21mraDS_iJBpIfQQtsY3ARQrIJQ/viewform">here</a-->
	<!--strong> Update 7 June 2021: </strong>We accepted 2 shared task submissions, 5 regular workshop papers and 12 extended abstracts! Details <a href="#papers">here</a-->
      </div>
	<!--div class="alert alert-danger" role="alert">
	<strong> Update 26 April 2021: </strong>We extended the deadlines for regular papers, extended abstracts and shared task participation. Details <a href="#dates">here</a>.
      </div-->
      <!--div class="alert alert-danger" role="alert">
	<strong>Update 14 April 2021: </strong>The evaluation phase of the shared task has now started. Information for late registration can be found <a href="#task">here</a>.
      </div-->
      <!--div class="alert alert-success" role="alert">
	<strong>Update 22 March 2021: </strong> We updated (manually verified) the development data of the shared task, which can be found <a href="#task">here</a>.
      </div>
      <div class="alert alert-success" role="alert">
	<strong>Update 9 March 2021: </strong> We are excited to announce our invited speakers: <a href="#speakers">Martha Palmer and Chris Potts</a>!
      </div-->
      <br/>
      
      <p>Recent developments in NLP have led to excellent performance on various semantic tasks. However, an important question that remains open is whether such methods are actually capable of modeling how linguistic meaning is shaped and influenced by context, or if they simply learn superficial patterns that reflect only explicitly stated aspects of meaning. An interesting case in point is the interpretation and understanding of <i>implicit</i> or <i>underspecified</i> language.</p>

      <p>More concretely, language utterances may contain <i>empty</i> or <i>fuzzy</i> elements, such as the following:  units of measurement, as in "she is 30" vs. "it costs 30" (30 what?), bridges and other missing links, as in "she tried to enter the car, but the door was stuck" (the door of what?), implicit semantic roles, as in "I met her while driving" (who was driving?), and various sorts of gradable phenomena; is a "small elephant" smaller than a "big bee"? Where is the boundary between "orange" and "red"?</p>

      <p><i>Implicit</i> and <i>underspecified</i> phenomena have been studied in linguistics and philosophy for decades (Sag, 1976; Heim, 1982; Ballmer and Pinkal, 1983), but empirical studies in NLP are scarce and far between. The number of datasets and task proposals is however growing (Roesiger et al., 2018; Elazar and Goldberg, 2019; Ebner et al., 2020; McMahan and Stone, 2020) and recent studies have shown the difficulty of annotating and modeling implicit and underspecified phenomena (Shwartz and Dagan, 2016; Scholman and Demberg, 2017; Webber et al., 2019).</p>
      
      <p>The use of <i>implicit</i> and <i>underspecified</i> terms poses serious challenges to standard natural language processing models, and they often require incorporating greater context, using symbolic inference and  common-sense reasoning, or more generally, going <i>beyond</i> strictly lexical and compositional meaning constructs. This challenge  spans all phases of the NLP model's life cycle: from collecting and annotating relevant data, through devising computational methods for modelling such phenomena, to evaluating and designing proper evaluation metrics.</p>
                  
      <p>Furthermore, most existing efforts in NLP are concerned with one particular problem, their benchmarks are narrow in size and scope, and no common platform or standards exist for studying effects on downstream tasks. In our opinion, interpreting  <i>implicit</i> and <i>underspecified</i> language is an inherent part of natural language understanding, these elements are essential for  human-like interpretation, and  modeling them may be critical for downstream applications.</p>

      <p>The goal of this workshop is to bring together theoreticians and practitioners from the entire NLP cycle, from annotation and benchmarking to modeling and applications, and to provide an umbrella for the development, discussion and standardization of the study of understanding implicit and underspecified language. <!--We explicitly encourage papers that propose new benchmarks, models and evaluation schemes that facilitate the interpretation or identification of implicit and underspecified utterances, including but not limited to: empty syntactic elements (verb-phrase ellipsis and syntactic gaps), implicit semantic roles, bridging anaphora, gradable/imprecise terms, and fused heads.</p-->We solicit papers on the following, and other, topics:</p>

      <ul>
	<li>Verb-phrase ellipsis and syntactic gaps</li>
	<li>Implicit semantic roles and semantic relations</li>
	<li>Bridging anaphora</li>
	<li>Gradable/imprecise terms</li>
	<li>Fused heads</li>
	<li>Other phenomena that involve underspecification or implicit information</li>
      </ul>
      
      <a name="speakers"></a>
      <div class="page-header">
	<h1>Invited Speakers</h1>
      </div>
      <div class="row">
	<div class="col-sm-6">
	  <div class="panel panel-default">
	    <div class="panel-heading">
	      <h2 class="panel-title"><a href="https://www.colorado.edu/faculty/palmer-martha/">Martha Palmer</a></h2>University of Colorado at Boulder
	    </div>
	    <div class="panel-body">
	      <b>Transcending Dependencies</b><br/>
	      This talk will discuss symbolic representations of sentences in context, ranging from universal dependencies to abstract meaning representations (AMR), and examine their capability for capturing certain aspects of meaning.  A main focus will be the ways in which AMR's can be expanded to encompass figurative language, the recovery of implicit arguments and relations between events. These examples will be primarily in English, and indeed some features of AMR are fairly English-centric. The talk will conclude by introducing Uniform Meaning Representations, a multi-sentence annotation scheme that is revising AMR’s to make them more suitable for other languages, especially low resource languages, and expanding the annotation guidelines to include Number, Tense, Aspect and Modality as well as Temporal Relations.
	    </div>
	  </div>
	</div>
	<div class="col-sm-6">
	  <div class="panel panel-default">
	    <div class="panel-heading">
	      <h2 class="panel-title"><a href="https://web.stanford.edu/~cgpotts/">Chris Potts</a></h2>Stanford University
	    </div>
	    <div class="panel-body">
	      <b>Improving NLP systems with Questions Under Discussion</b><br/>
	      Questions Under Discussion (QUDs) have come to occupy a central place in theories of pragmatics. QUDs are abstract, implicit questions that evolve along with the discourse, determining what is relevant and shaping speaker choices and listener inferences. QUDs have been identified as a factor in numerous diverse phenomena, including discourse particles, presuppositions, intonational meaning, and conversational implicatures. How can we leverage these insights to create better large-scale NLP systems? In this talk, I'll survey a range of approaches to modeling (or approximating) QUDs in ways that are scalable and easy to integrate into standard NLP architectures. In addition, I'll identify NLP tasks that can clearly benefit from QUDs. Free-form dialogue applications tend to come to mind first, and the value of QUDs for such tasks seems clear, so I will concentrate on simpler generation tasks &ndash; especially image description and question answering &ndash; that can benefit from QUD-based control.
	    </div>
	  </div>
	</div>
      </div>
      
    <a name="task"></a>
    <div class="page-header">
      <h1>Shared Task</h1>
    </div>

      <p>As part of the workshop, we are organizing a shared task on implicit and underspecified language. The focus of this task is on modeling the necessity of clarifications due to aspects of meaning that are implicit or underspecified in context. Specifically, the task setting follows the recent proposal of predicting revision requirements in collaboratively edited instructions (Bhat et al., 2020). The data consists of instances from wikiHowToImprove (Anthonio et al., 2020) in which a revision resolved an implicit or underspecified linguist element. The following revision types are part of the data:</p>
	<ul>
	  <li>Replacements of pronouns with more precise noun phrases</li>
	  <li>Replacements of 'do' as a full verb with more precise verbs</li>
	  <li>Insertions of optional verbal phrase complements</li> 
	  <li>Insertions of adverbial and adjectival modifiers</li>
	  <li>Insertions of logical quantifiers and modal verbs</li> 
	</ul>

      <p>Final training and development sets are available here:</p>
      <ul>
	<li><a href="data/shared_task_traindata_march5.tsv.gz">Training data (unverified)</a></li>
	<!--li><a href="data/shared_task_devdata_jan29.tsv.gz">Development data (will be manually verified)</a></li-->
        <li><a href="data/shared_task_devdata_mar22.tsv.gz">Development data (manually verified)</a></li>
	<li><a href="https://raw.githubusercontent.com/unimplicit/unimplicit.github.io/master/data/README">README (updated 5 March 2021)</a></li>
      </ul>
      <p>Access to the test data requires registration as a participant. If you are interested in participating in the shared task, please contact <a href="mailto:michael.roth@ims.uni-stuttgart.de">Michael Roth</a>.</p>      
      
      <!--a name="call"></a>
      <div class="page-header">
	<h1>Call for Submissions</h1>
      </div>
      <p>We invite both long (8 pages) and short (4 page) papers. The limits refer to
	the content and any number of additional pages for references are allowed. The
	papers should follow the ACL-IJCNLP 2021 formatting instructions
	(see <a href="https://2021.aclweb.org/calls/papers/#paper-submission-information">https://2021.aclweb.org/calls/papers/</a>).</p>

<p>Each submission must be anonymized, written in English, and contain a title and abstract. We specifically encourage papers that address the following themes, for a single phenomenon or a set of phenomena:</p>

<ul>
  <li>New benchmarks for implicit/underspecified phenomena</li>
  <li>Models and modeling strategies for uncovering implicit/underspecified phenomena</li>
  <li>Evaluation schemes and metrics for the identification and interpretation of implicit and underspecified ut\
    terances</li>
  <li>Implicit/Underspecified phenomena that are not yet within reach with current NLP technology.</li>
</ul>

  <p>To encourage discussion and community building and to bootstrap potential collaborations, we elicit, in addition to shared task papers and regular "archival" track papers, also non-archival submissions. These can take two forms:</p>
  
  <ul>
    <li>Works in progress, that are not yet mature enough for a full submission, can be submitted in the form of a title and abstract. Abstracts may be up to two pages in length.</li>
    <li>Already published work, or work currently under submission elsewhere, can be submitted in the form of the original abstract and a copy of the submission/publication.</li>
  </ul>

      <p>These works will be reviewed for topical fit and accepted submissions will be presented as posters (in gather.town or similar interface). Depending on the final workshop program, selected works <i>may</i> be presented in panels. We plan for these to be an opportunity for researchers to present and discuss their work with the relevant community.</p>
      
      
<p>Please submit your papers at <a href="https://www.softconf.com/acl2021/w19_UnImplicit/">https://www.softconf.com/acl2021/w19_UnImplicit/</a></p-->
																		 
																		       
      <a name="program"></a>
      <div class="page-header">
	<h1>Workshop Program</h1><br/>
	(all times shown in UTC+2)
      </div>
<p>
  <table class="table table-striped">
    <tbody>
      <tr>
	<td>16:50</td>
	<td>Opening <small class="text-muted">(Zoom)</small></td>
      </tr>
      <tr>
	<td class="success">17:00</td>
	<td>
	  <b>Invited talk</b> <small class="text-muted">(Zoom)</small><br/>
	  <!-- title <br/-->
	  <i>Martha Palmer</i> <sup><a href="slides/TranscendImplicitACL-July2021.pdf">[slides]</a></sup></td>
      </tr>
      <tr>
	<td class="success">18:00</td>
	<td><b>Poster session I</b> <small class="text-muted">(Gather.town)</small></td></td>
      </tr>
      <tr>
	<td class="success"></td><td>Let's be explicit about that: Distant supervision for implicit discourse relation classification via connective prediction <small class="text-muted">(Poster 3)</small><br/>
	  <i>Murathan Kurfalı and Robert Östling</i></td></tr>
      <tr>
	<td class="success"></td><td>Implicit Phenomena in Short-answer Scoring Data <small class="text-muted">(Poster 9x)</small><br/>
	  <i>Marie Bexte, Andrea Horbach and Torsten Zesch</i></td></tr>
      <tr>
	<td class="success"></td><td>Evaluation Guidelines to Deal with Implicit Phenomena to Assess Factuality in Data-to-Text Generation <small class="text-muted">(Poster 18)</small><br/>
	  <i>Roy Eisenstadt and Michael Elhadad</i></td></tr>
      <tr>
	<td class="success"></td><td>UnImplicit Shared Task Report: Detecting Clarification Requirements in Instructional Text <small class="text-muted">(Poster A, right of 3956)</small> <br/>
	  <i>Michael Roth and Talita Anthonio</i></td></tr>      
      <tr>
	<td class="info"><b>Abstracts</b></td><td>Is Sluice Resolution really just Question Answering? <small class="text-muted">(Poster 1)</small><br/>
          <i>Peratham Wiriyathammabhum</i></td></tr>
      <tr>
	<td class="info"></td><td>Decontextualization: Making Sentences Stand-Alone <small class="text-muted">(Poster B, below 9x)</small><br/>
	  <i>Eunsol Choi, Jennimaria Palomaki, Matthew Lamm, Tom Kwiatkowski, Dipanjan Das and Michael Collins</i></td></tr>
      <tr>
	<td class="info"></td><td>(Re)construing meaning in NLP <small class="text-muted">(Poster C, below 17x)</small><br/>
	  <i>Sean Trott, Tiago Timponi Torrent, Nancy Chang and Nathan Schneider</i></td></tr>
      <tr>
	<td class="info"></td><td>Modelling Entity Implicature based on Systemic Functional Linguistics <small class="text-muted">(Poster D, below 3956)</small><br/>
	  <i>Hawre Hosseini, Mehran Mansouri and Ebrahim Bagheri</i></td></tr>
      <tr>
	<td class="info"></td><td>Meaning Representation of Numeric Fused-Heads in UCCA <small class="text-muted">(Poster 12)</small><br/>
	  <i>Ruixiang Cui and Daniel Hershcovich</i></td></tr>
      <tr>
	<td class="info"></td><td>Underspecification in Executable Instructions <small class="text-muted">(Poster 13)</small><br/>
	  <i>Valentina Pyatkin, Royi Lachmy and Reut Tsarfaty</i></td></tr>
      <tr>
	<td class="danger"><b>Findings</b></td><td>Investigating Transfer Learning in Multilingual Pre-trained Language Models through Chinese Natural Language Inference <small class="text-muted">(Poster E, right of D)</small><br/>
	  <i>Hai Hu, Yiwen Zhang, Yina Patterson, Yanting Li, Yixin Nie and Kyle Richardson</i></td></tr>
      <tr>
	<td class="success">19:00</td>
	<td><b>Working group session I (discussion / presentation)</b> <small class="text-muted">(Gather.town)</small>
	  <br/><!--Anyone interested can fill out this survey in advance: <a href="https://docs.google.com/forms/d/e/1FAIpQLScuIo3ITDr-GUWY93aW59x21mraDS_iJBpIfQQtsY3ARQrIJQ/viewform">Google form</a-->
	    <b>A.</b> Challenges and best-practices in data collection and annotation of implicit phenomena <small class="text-muted"> (follow Yoav Goldberg)</small><br/>
	    <b>B.</b> What is the range of implicit phenomena? (produce a taxonomy) <small class="text-muted"> (follow Reut Tsarfaty)</small><br/>
	    <b>C.</b> What are the next steps in implicit and underspecified language research? <small class="text-muted"> (follow Michael Roth)</small><br/>
      </td></tr>
      <tr>
	<td class="success">20:00</td>
	<td><b>Poster session II</b> <small class="text-muted">(Gather.town)</small></td></td>
      </tr>
      <tr>	
	<td class="success"></td><td>Improvements and Extensions on Metaphor Detection <small class="text-muted">(Poster 2)</small><br/>
	  <i>Weicheng Ma, Ruibo Liu, Lili Wang and Soroush Vosoughi</i></td></tr>
      <tr>
	<td class="success"></td><td>Human-Model Divergence in the Handling of Vagueness <small class="text-muted">(Poster 4)</small><br/>
	  <i>Elias Stengel-Eskin, Jimena Guallar-Blasco and Benjamin Van Durme</i></td></tr>
      <tr>
	<td class="success"></td><td>TTCB System Description to a Shared Task on Implicit and Underspecified Language 2021 <small class="text-muted">(Poster 21)</small><br/>
	  <i>Peratham Wiriyathammabhum</i></td></tr>
      <tr>
	<td class="success"></td><td>A Mention-Based System for Revision Requirements Detection <small class="text-muted">(Poster 22)</small><br/>
	  <i>Ahmed Ruby, Christian Hardmeier and Sara Stymne</i>/</td></tr>
      <tr>
	<td class="info"><b>Abstracts</b></td><td>Superlatives in Discourse: Explicit and Implicit Domain Restrictions for Superlatives <small class="text-muted">(Poster 14)</small><br/>
	  <i>Valentina Pyatkin, Ido Dagan and Reut Tsarfaty</i></td></tr>
      <tr>
	<td class="info"></td><td>Transformer-based language models and complement coercion: Experimental studies <small class="text-muted">(Poster 15)</small><br/>
	  <i>Yuling Gu</i></td></tr>
      <tr>
	<td class="info"></td><td>Large Scale Crowdsourcing of Noun-Phrase Links <small class="text-muted">(Poster 16)</small><br/>
	  <i>Victoria Basmov, Yanai Elazar, Yoav Goldberg and Reut Tsarfaty</i></td></tr>
      <tr>
	<td class="info"></td><td>Variation in conventionally implicated content: An empirical study in English and German <small class="text-muted">(Poster 17x)</small><br/>
	  <i>Annette Hautli-Janisz and Diego Frassinelli</i></td></tr>
      <tr>
	<td class="info"></td><td>Challenges in Detecting Null Relativizers in African American Language for Sociolinguistic and Psycholinguistic Applications <small class="text-muted">(Poster 18/C)</small><br/>
	  <i>Anissa Neal, Brendan O'Connor and Lisa Green</i></td></tr>
      <tr>
	<td class="info"></td><td>Incorporating Human Explanations for Robust Hate Speech Detection <small class="text-muted">(Zoom(!)---instead of Poster A)</small><br/>
	  <i>Jennifer Chen, Faisal Ladhak, Daniel Li and Noémie Elhadad</i></td></tr>
      <tr>
	<td class="danger"><b>Findings</b></td><td>John praised Mary because _he_? Implicit Causality Bias and Its Interaction with Explicit Cues in LMs <small class="text-muted">(Poster 3956)</small><br/>
	  <i>Yova Kementchedjhieva, Mark Anderson and Anders Søgaard</i></td></tr>      
      <tr>
	<td class="success">20:55</td>
	<td>
	  <b>Invited talk</b> <small class="text-muted">(Zoom)</small><br/>
	  <i>Chris Potts <sup><a href="slides/potts-unimplicit2021-slides-handout.pdf">[slides]</a></sup></i>
	</td>
      </tr>
      <tr>
	<td class="success">22:00</td>
	<td><b>Working group session II (discussion / presentation)</b> <small class="text-muted">(Gather.town)</small>
	  <br/>
	    <b>D.</b> ML-based modeling of different implicit-language phenomena/tasks <small class="text-muted">(follow Yoav Goldberg)</small><br/>
	    <b>E.</b> What are the existing and/or possible NLP tasks around implicit phenomena? <small class="text-muted">(follow Reut Tsarfaty)</small><br/>
	    <b>F.</b> What would be a good shared task around implicit and underspecified language? <small class="text-muted">(follow Michael Roth)</small><br/>
      </td></tr>
      <tr>
	<td>22:45</td>
	<td>(Official) closing</td>
      </tr>
    </tbody>
  </table>
</p>











<!--
<h3>Non-archival papers/abstracts</h3>
<p>Superlatives in Discourse: Explicit and Implicit Domain Restrictions for Superlatives<br/>
  <i>Valentina Pyatkin, Ido Dagan and Reut Tsarfaty</i></p>
<p>Transformer-based language models and complement coercion: Experimental studies<br/>
  <i>Yuling Gu</i></p>
<p>Large Scale Crowdsourcing of Noun-Phrase Links<br/>
  <i>Victoria Basmov, Yanai Elazar, Yoav Goldberg and Reut Tsarfaty</i></p>
<p>Variation in conventionally implicated content: An empirical study in English and German<br/>
  <i>Annette Hautli-Janisz and Diego Frassinelli</i></p>
<p>Challenges in Detecting Null Relativizers in African American Language for Sociolinguistic and Psycholinguistic Applications<br/>
  <i>Anissa Neal, Brendan O'Connor and Lisa Green</i></p>
<p>Incorporating Human Explanations for Robust Hate Speech Detection<br/>
  <i>Jennifer Chen, Faisal Ladhak, Daniel Li and Noémie Elhadad</i></p-->
    
  <a name="dates"></a>
  <div class="page-header">
    <h1>Important Dates</h1>
  </div>
      <ul>
	<li><del>December 21, 2020: First call for workshop papers</del></li>
	<li><del>February 15, 2021: Second call for workshop papers</del></li>
	<li><del>April 14, 2021: Start of shared task evaluation</del></li>
	<li><del>April 30, 2021: Regular workshop paper due date</del></li>
	<li><del>May 3, 2021: End of shared task evaluation</del></li>
	<li><del>May 21, 2021: Shared task papers due date</del></li>
	<li><del>May 28, 2021: Notification of acceptance</del></li>
	<li><del>June 7, 2021: Camera-ready papers due</del></li>
	<li>August 5, 2021: Workshop date</li>
      </ul>

      All deadlines are 11:59PM UTC-12:00 ("anywhere on Earth").
      
      <a name="organizers"></a>
      <div class="page-header">
	<h1>Organizers</h1>
      </div>
      <ul class="list-unstyled">
	<li><a target="_blank" href="https://www.ims.uni-stuttgart.de/en/institute/team/Roth-00006/">Michael Roth</a>, Stuttgart University</li>
	<li><a target="_blank" href="https://research.biu.ac.il/researcher/prof-reut-tsarfaty/">Reut Tsarfaty</a>, Bar-Ilan University</li>
	<li><a target="_blank" href="https://www.cs.bgu.ac.il/~yoavg/uni/">Yoav Goldberg</a>, Bar-Ilan University and AI2</li>	
      </ul>

      <h3>Program Committee<a name="committee" ></a></h3>

      <ul class="list-unstyled">
	<li>Omri Abend, Hebrew University of Jerusalem</li>
	<li>Johan Bos, University of Groningen</li>
	<li>Nancy Chang, Google</li>
	<!--li>Ido Dagan, Bar-Ilan University</li-->
	<li>Vera Demberg, Saarland University</li>
	<li>Katrin Erk, University of Texas at Austin</li>
	<!--li>Antske Fokkens, Vrije Universiteit Amsterdam</li-->
	<li>Annemarie Friedrich, Bosch Center for Artificial Intelligence</li>
	<li>Dan Goldwasser, Purdue University</li>
	<li>Yufang Hou, IBM Research Ireland</li>
	<li>Ruihong Huang, Texas A&amp;M University</li>
	<li>Mirella Lapata, University of Edinburgh</li>
	<li>Junyi Jessy Li, University of Texas at Austin</li>
	<li>Ray Mooney, University of Texas at Austin</li>
	<li>Philippe Muller, University of Toulouse</li>
	<li>Vincent Ng, University of Texas at Dallas</li>
	<li>Tim O'Gorman, University of Massachusetts Amherst</li>
	<li>Karl Pichotta, Memorial Sloan Kettering Cancer Center</li>
	<li>Massimo Poesio, Queen Mary University</li>
	<li>Niko Schenk, Amazon</li>
	<li>Nathan Schneider, Georgetown University</li>
	<li>Vered Shwartz, Allen Institute for AI &amp; University of Washington</li>
	<li>Elior Sulem, University of Pennsylvania</li>
	<li>Sara Tonelli, Fondazione Bruno Kessler</li>
	<li>Ben Van Durme, Johns Hopkins University &amp; Microsoft Semantic Machines</li>
	<li>Luke Zettlemoyer, University of Washington &amp; Facebook</li>
      </ul>

      <br/>
      <br/>
      <br/>
      
    </div>    
  </body>
</html>
