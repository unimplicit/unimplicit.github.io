<!DOCTYPE html>
<html lang="en">

  <head>
    <title>
      UnImplicit: Understanding Implicit and Underspecified Language
    </title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Prevent caching -->
    <META HTTP-EQUIV="Pragma" CONTENT="no-cache">
    <META HTTP-EQUIV="Expires" CONTENT="-1">
    <link href="bootstrap/css/bootstrap.min.css" rel="stylesheet" media="screen">
    
    <style>
      /* Customize container */
      @media (min-width: 968px) {
	  .container {
	      max-width: 968px;
	  }
      }
      .container-narrow > hr {
	  margin: 30px 0;
      }
      
      /* Customize dropdown menu */
      .dropdown {
	  cursor: pointer;
      }
      .dropdown sup {
	  color: rgb(66, 139, 202);
      }
      .dropdown sup:hover, .dropdown sup:focus {
	  color: rgb(42, 100, 150);
	  text-decoration: underline;
      }
      .dropdown-menu {
	  min-width: 500px;
	  left: -200px;
      }
      .dropdown-menu li {
	  margin-bottom: .5em;
	  /*border-top-style:solid; padding-left:10px;*/
      }
    </style>
  </head>
  
  <body data-spy="scroll" data-target="#navbar" data-offset="70" onload="load()">
    
    <nav class="navbar navbar-default navbar-fixed-top" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="#">UnImplicit</a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            <li><a href="#task">Shared Task</a></li>
            <li><a href="#organizers">Organizers &amp; Committee</a></li>
          </ul>
          <ul class="nav navbar-nav navbar-right">
            <!--li><a href="https://www.emnlp-ijcnlp2019.org/">EMNLP-IJCNLP 2019</a></li-->
          </ul>
        </div>
      </div>
    </nav>
    
    <div class="container">
      
      <br/>
      <br/>      
      <br/>
      <center><h2 id="top"><b>UnImplicit: The First Workshop on<br/>
	    Understanding Implicit and Underspecified Language</b></h2></center>
      <center><h4>Date and location TBD</h4></center>
      <br/>
      
      <p>Recent developments in NLP have led to excellent performance on various semantic tasks. However, an important question that remains open is whether such methods are actually capable of modeling how linguistic meaning is shaped and influenced by context, or if they simply learn superficial patterns that reflect only explicitly stated aspects of meaning. An interesting case in point is the interpretation and understanding of <i>implicit</i> or <i>underspecified</i> language.</p>

      <p>Specifically, language utterances may contain <i>empty</i> or <i>fuzzy</i> elements, such as the following:  units of measurement, as in "she is 30" vs. "it costs 30" (30 what?), bridges and other missing links, as in "she tried to enter the car, but the door was stuck" (the door of what?), implicit semantic roles, as in "I met her while driving" (who was driving?), and various sorts of gradable phenomena; is a "small elephant" smaller than a "big bee"? Where is the boundary between "orange" and "red"?</p>

      <p>The use of <i>implicit</i> and <i>underspecified</i> terms poses serious challenges to standard natural language processing models, and they often require incorporating greater context, using symbolic inference and  common-sense reasoning, or more generally, going <i>beyond</i> strictly lexical and compositional meaning constructs. This challenge  spans all phases of the NLP model's life cycle: from collecting and annotating relevant data, through devising computational methods for modelling such phenomena, to evaluating and designing proper evaluation metrics.</p>
      
      
      <p>Implicit and underspecified phenomena have been studied in linguistics and philosophy for decades (Sag, 1976; Heim, 1982; Ballmer and Pinkal, 1983), but empirical studies in NLP are scarce and far between. The number of datasets and task proposals is however growing (Roesiger et al., 2018; Elazar and Goldberg, 2019; Ebner et al., 2020; McMahan and Stone, 2020) and recent studies have shown the difficulty of annotating and modeling implicit and underspecified phenomena (Shwartz and Dagan, 2016; Scholman and Demberg, 2017; Webber et al., 2019).
      </p>
            
      <p>Furthermore, most existing efforts in NLP are concerned with one particular problem, their benchmarks are narrow in size and scope, and no common platform or standards exist for studying effects on downstream tasks. In our opinion, interpreting  <i>implicit</i> and <i>underspecified</i> language is an inherent part of natural language understanding, these elements are essential for  human-like interpretation, and  modeling them may be critical for downstream applications.</p>

      <p>The goal of this workshop is to bring together theoreticians and practitioners from the entire NLP cycle, from annotation and benchmarking to modeling and applications, and to provide an umbrella for the development, discussion and standardization of the study of understanding implicit and underspecified language. We explicitly encourage papers that propose new benchmarks, models and evaluation schemes that facilitate the interpretation or identification of implicit and underspecified utterances, including but not limited to: empty syntactic elements (verb-phrase ellipsis and syntactic gaps), implicit semantic roles, bridging anaphora, gradable/imprecise terms, and fused heads.</p>

    <a name="task"></a>
    <div class="page-header">
      <h4>Shared Task</h4>
    </div>

      <p>As part of the workshop, we plan to organize a shared task on implicit and underspecified language understanding. The focus of this task will be on modeling the necessity of clarifications due to aspects of meaning that are implicit or underspecified in context. Specif-ically, the task setting will follow the recently proposed task of predicting the need for revision (Bhat et al., 2020) and the data will consist of instances from wikiHowToImprove (Anthonio et al., 2020) that were annotated for context-specific phenomena. The data for the shared task is currently in the process of creation and will be completed by the end of 2020.</p>

      <a name="organizers"></a>
      <div class="page-header">
	<h1>Organizers</h1>
      </div>
      <ul class="list-unstyled">
	<li><a target="_blank" href="https://www.ims.uni-stuttgart.de/en/institute/team/Roth-00006/">Michael Roth</a>, Stuttgart University</li>
	<li><a target="_blank" href="https://research.biu.ac.il/researcher/prof-reut-tsarfaty/">Reut Tsarfaty</a>, Bar-Ilan University</li>
	<li><a target="_blank" href="https://www.cs.bgu.ac.il/~yoavg/uni/">Yoav Goldberg</a>, Bar-Ilan University and AI2</li>	
      </ul>

      <h3>Program Committee<a name="committee" ></a></h3>

      <ul class="list-unstyled">
	<li>Johan Bos</li>
	<li>Ido Dagan</li>
	<li>Vera Demberg</li>
	<li>Katrin Erk</li>
	<li>Antske Fokkens</li>
	<li>Annemarie Friedrich</li>
	<li>Dan Goldwasser</li>
	<li>Yufang Hou</li>
	<li>Ruihong Huang</li>
	<li>Mirella Lapata</li>
	<li>Junyi Jessy Li</li>
	<li>Ray Mooney</li>
	<li>Philippe Muller</li>
	<li>Vincent Ng</li>
	<li>Tim O'Gorman</li>
	<li>Karl Pichotta</li>
	<li>Massimo Poesio</li>
	<li>Nathan Schneider</li>
	<li>Vered Shwartz</li>
	<li>Elior Sulem</li>
	<li>Sara Tonelli</li>
	<li>Ben Van Durme</li>
	<li>Luke Zettlemoyer</li>
      </ul>

      <br/>
      <br/>
      <br/>
      
    </div>    
  </body>
</html>
